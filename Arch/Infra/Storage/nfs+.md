# 华为NFS+

https://we.yesky.com/blog/301070

[openEuler NFS+协议全新发布：实现NAS存储性能与可靠性倍增](https://www.openeuler.org/zh/blog/20230428-NFS/20230428-NFS.html)




下图是AI大模型训练过程中一个训练周期的过程图解。shuffle代表将训练模型的数据集打乱，相当于“洗牌”，可以增强算法的鲁棒性，从而加快模型的训练速度。R1-RN代表对每一个batch size数据集的读取。C1-CN代表对每一个bacth size数据集的训练。黄色的wait_read代表GPU闲置等待时间。


AI大模型训练时，采用数据预读取的方式进行，即边训练边读取，当GPU开始训练C1时，这时候可以预读取R2数据集。若存储性能足够强大，理想情况下每一个数据集的训练可以实现无缝衔接，即黄色的wait_read区域应该是不存在的。但实际情况往往并非如此，GPU会存在等待，以第一次出现的wait_read为例，由于存储对R3数据集的读取速度太慢，以至于GPU早已完成了对R2数据集的训练，但只能等存储读取完数据之后才能进行R3数据集的训练。

同理，强大的存储还能够缩短shuffle和CheckPoint保存的时间。为了应对在大模型训练过程中出现的GPU故障、网络故障、超参设置不合理等问题，需要定时保存CheckPoint，且保存CheckPoint时，GPU是需要停止训练的。CheckPoint是用来记录关键点的文件，类似于存储的“快照”功能，其功能是为了实现“断点续训”。时间就是金钱，GPU等待的每分每秒都是金钱在燃烧。

模型训练过程中存储与计算的交互特点可以总结为：以海量小文件读为主，涉及CheckPoint读写操作。也就是说，所有黄色的wait区域，存储都有大幅优化的空间，而IOPS和带宽成为存储性能的关键。鉴于大模型每分每秒都在烧钱，如果不重视存储，整个训练周期下来，黄色区域浪费掉的计算资源将会非常惊人。

这只是存储关键价值的一个典型场景。那么综合来看，AI大模型究竟需要什么样的存储？

第一，数据共享是多个分布式节点训练场景下的存储首要诉求。随着大模型的参数规模越来越大，往往需要几十上百个节点并发训练，若仍采用本地盘的形式，各节点缓存相同副本导致数据成本较高，且本地盘的可扩展性差，单节点SSD能力存在瓶颈，无法实现数据共享。此时，便对数据共享提出了强烈诉求，能够支持数据的高效流转。

第二，海量数据高并发处理能力是大模型时代存储的核心诉求之一。以GPT-4为例，其原始数据集规模已达PB级。AI大模型需要处理海量小文件训练样本，对应海量的元数据操作，同时也要兼顾大文件处理。服务器客户端与存储节点之间要具备高并发，us级低时延的能力。这些都需要存储具有并发访问的能力。

第三，强大的读写性能。在大模型训练阶段，对训练数据样本存储要读得快，对CheckPoint大文件保存也要写的快，将wait时长无限降低，尽可能减少GPU闲置等待时间，提升模型训练效率。这需要存储在大小文件场景下都能提供高性能。

第四，数据存储的高可靠、高安全要求。行业大模型中的数据属于私域数据，其独有的高安全、高可靠性属性且包含敏感信息，要求要有数据备份、远程复制等。CheckPoint是关键性文件，其保存同样需要高性能存储增加可靠性。保障模型训练的稳定性，就是省钱。

第五，向量数据库的快速检索、低时延要求。向量数据库可以一定程度上避免大模型幻觉，及时更新最新的新闻数据等，加强对私域数据的保护。向量数据库是对共有数据集和行业数据集的向量化，由此生成的数据库，可以部署在推理侧，大大加快模型的推理速度。因此，同样需要高性能存储保存向量数据库，加快检索速度。

根据以上这些核心诉求，什么才是适配AI大模型时代的存储，答案已经非常清晰：高性能高可靠的并行文件存储。

并行文件存储支持使用多个 IO 路径将数据读/写到多个存储设备，同时可横向扩展容纳PB级数据，并支持高带宽，天然适配AI大模型对存储的要求。