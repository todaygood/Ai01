# 摩尔线程


## 产品：S4000

S4000是2023年12月发布的，采用第三代MUSA内核，单卡支持48GB显存和768GB/s的显存带宽。基于摩尔线程自研MTLink1.0技术（类似英伟达NvLink），S4000可以支持多卡互联，另外，借助摩尔线程自研MUSIFY开发工具，S4000计算卡可以充分利用现有CUDA软件生态，实现CUDA代码零成本迁移到MUSA平台，这也在很大程度上解决了人们常常提到的“生态”问题。

参见： https://www.mthreads.com/news/146

目前，摩尔线程支持包括LLaMA、GLM、Aquila、Baichuan、GPT、Bloom、玉言等各类主流大模型的训练和微调。基于摩尔线程KUAE千卡集群，70B到130B参数的大模型训练，线性加速比均可达到91%，算力利用率基本保持不变。以2000亿训练数据量为例，智源研究院700亿参数Aquila2可在33天完成训练；1300亿参数规模的模型可在56天完成训练。此外，摩尔线程KUAE千卡集群支持长时间连续稳定运行，支持断点续训，异步Checkpoint少于2分钟。

 
对于计算加速显卡，大家可能也想知道它与同行的性能对比，由于计算加速卡并不是面向消费端的，也不能用能跑什么游戏来比较，一般的，是比较它的浮点运算速度。

首先，粗略了解一下浮点数，浮点数（Floating-point number）是计算机用来近似表示实数的一种数学表达方法，其设计的核心目的是为了表示非常大的数，或者非常精确的小数。

参见： https://mp.weixin.qq.com/s/u-hwp7kBTW7fOgDlNNKkRQ


## KuAE 

参见[KuAE架构](./kuae_arch1.png)


摩尔线程KUAE千卡计算集群凭借高兼容性、高稳定性、高扩展性和高算力利用率等综合优势，将成为大模型训练坚实可靠的先进基础设施。

实际应用方面，摩尔线程首个全国产GPU千卡千亿模型训练平台——摩尔线程KUAE智算中心12月份在北京建立，支持包括LLaMA、GLM、Aquila、Baichuan、GPT、Bloom、玉言等各类主流大模型的训练和微调。基于摩尔线程KUAE千卡集群，70B到130B参数的大模型训练，线性加速比均可达到91%，算力利用率基本保持不变。以2000亿训练数据量为例，智源研究院700亿参数Aquila2可在33天完成训练；1300亿参数规模的模型可在56天完成训练。


基础设施：包含KUAE计算集群、RDMA网络与分布式存储。此次发布的摩尔线程KUAE千卡模型训练平台，建设周期只需30天，支持千亿参数模型的预训练、微调和推理，可实现高达91%的千卡集群性能扩展系数。基于MTT S4000和双路8卡GPU服务器MCCX D800，摩尔线程KUAE集群支持从单机多卡到多机多卡，从单卡到千卡集群的无缝扩展，未来将推出更大规模的集群，以满足更大规模的大模型训练需求。

 

▽ KUAE Platform集群管理平台：用于AI大模型训练、分布式图形渲染、流媒体处理和科学计算的软硬件一体化平台，深度集成全功能GPU计算、网络和存储，提供高可靠、高算力服务。通过该平台，用户可灵活管理多数据中心、多集群算力资源，集成多维度运维监控、告警和日志系统，帮助智算中心实现运维自动化。

 

▽ KUAE ModelStudio模型服务：覆盖大模型预训练、微调和推理全流程，支持所有主流开源大模型。通过摩尔线程MUSIFY开发工具，可以轻松复用CUDA应用生态，内置的容器化解决方案，则可实现API一键部署。该平台意在提供大模型生命周期管理，通过简洁、易操作的交互界面，用户可按需组织工作流，大幅降低大模型的使用门槛。

