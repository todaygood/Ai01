# Google Gemini 1.5

🚀 Google Gemini 1.5发布，虽然没有水花但功能强大

在大家的目光都被 Sora 吸引的同时，谷歌也发布了 Google Gemini 1.5。但就好像每次汪峰想开演唱会总被其他新闻抢头条一样，Gemini 1.5 这次也没有抢到多少版面。不过玩笑归玩笑，这次 Gemini 1.5 的更新可一点没含糊；它在跨模态超长文本理解能力上的大幅突破。Gemini 1.5 能够稳定处理的信息量高达 100 万个 tokens。相当于 1 小时的视频、11 小时的音频、超过 3 万行代码或 70 万个单词。而之前保持记录的 Claude 2.1 则是 20 万 tokens，Gemini 1.5 这次直接将这个数字翻了 5 倍，在窗口长、度上成功碾压了市面上所有大模型。

这还不是谷歌的极限，他们已经成功测试了高达 1000 万 tokens，相当于一次将整个《指环王》三部曲放进去。除了 100 万个 tokens 外，它还有更高效的 MoE 架构。和 Transformer 相比，MoE 的响应更快、质量更高，能大大提升模型的效率和准确性。不仅更适应处理大规模数据集的复杂任务，还有更强的可扩展性和灵活性。

Gemini 1.5 另一个值得关注的功能是，它可以对上传内容进行无缝分析、分类和总结大量内容。例如，当给出阿波罗 11 号登月任务的 402 页记录时，它可以推理整个文档中的对话、事件和细节。而在超长视频理解上 Gemini 1.5 也同样毫不拉跨， 它甚至能读取一部上世纪 44 分钟的无声电影，并准确回答类似 “纸张从口袋取出的时间“ 这样精准的细节。

而在读取代码上 Gemini 1.5 也很强大，它能深入分析整个代码库。例如投喂给它一个 81.6 万 tokens、超过 10 万行代码的提示时，它可以根据问题迅速找到特定 demo 的代码，还能提出有用的修改建议并进行解释。

最后也是最亮眼的功能是 in-context learning。在研究人员测试一个不到 200 人使用的小众语言“Kalamang”时，Gemini 1.5 可以自我学习，并且能够执行从英语到 Kalamang 的翻译任务。
