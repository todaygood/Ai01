# 大模型 

大模型是指具有大规模参数和复杂计算结构的机器学习模型。

大模型本质上是一个使用海量数据训练而成的深度神经网络模型，其巨大的数据和参数规模，实现了智能的涌现，展现出类似人类的智能。

那么，大模型和小模型有什么区别？

小模型通常指参数较少、层数较浅的模型，它们具有轻量级、高效率、易于部署等优点，适用于数据量较小、计算资源有限的场景，例如移动端应用、嵌入式设备、物联网等。

而当模型的训练数据和参数不断扩大，直到达到一定的临界规模后，其表现出了一些未能预测的、更复杂的能力和特性，模型能够从原始训练数据中自动学习并发现新的、更高层次的特征和模式，这种能力被称为“涌现能力”。而具备涌现能力的机器学习模型就被认为是独立意义上的大模型，这也是其和小模型最大意义上的区别。

相比小模型，大模型通常参数较多、层数较深，具有更强的表达能力和更高的准确度，但也需要更多的计算资源和时间来训练和推理，适用于数据量较大、计算资源充足的场景，例如云端计算、高性能计算、人工智能等。

2. 大模型相关概念区分：

大模型（Large Model,也称基础模型，即Foundation Model），是指具有大量参数和复杂结构的机器学习模型，能够处理海量数据、完成各种复杂的任务，如自然语言处理、计算机视觉、语音识别等。

超大模型：超大模型是大模型的一个子集，它们的参数量远超过大模型。

大语言模型（Large Language Model）：通常是具有大规模参数和计算能力的自然语言处理模型，例如 OpenAI 的 GPT-3 模型。这些模型可以通过大量的数据和参数进行训练，以生成人类类似的文本或回答自然语言的问题。大型语言模型在自然语言处理、文本生成和智能对话等领域有广泛应用。

GPT（Generative Pre-trained Transformer）：GPT 和ChatGPT都是基于Transformer架构的语言模型，但它们在设计和应用上存在区别：GPT模型旨在生成自然语言文本并处理各种自然语言处理任务，如文本生成、翻译、摘要等。它通常在单向生成的情况下使用，即根据给定的文本生成连贯的输出。

ChatGPT：ChatGPT则专注于对话和交互式对话。它经过特定的训练，以更好地处理多轮对话和上下文理解。ChatGPT设计用于提供流畅、连贯和有趣的对话体验，以响应用户的输入并生成合适的回复。

3. 大模型的发展历程


萌芽期（1950-2005）：以CNN为代表的传统神经网络模型阶段

· 1956年，从计算机专家约翰·麦卡锡提出“人工智能”概念开始，AI发展由最开始基于小规模专家知识逐步发展为基于机器学习。

· 1980年，卷积神经网络的雏形CNN诞生。

· 1998年，现代卷积神经网络的基本结构LeNet-5诞生，机器学习方法由早期基于浅层机器学习的模型，变为了基于深度学习的模型,为自然语言生成、计算机视觉等领域的深入研究奠定了基础，对后续深度学习框架的迭代及大模型发展具有开创性的意义。

探索沉淀期（2006-2019）：以Transformer为代表的全新神经网络模型阶段

· 2013年，自然语言处理模型 Word2Vec诞生，首次提出将单词转换为向量的“词向量模型”，以便计算机更好地理解和处理文本数据。

· 2014年，被誉为21世纪最强大算法模型之一的GAN（对抗式生成网络）诞生，标志着深度学习进入了生成模型研究的新阶段。

· 2017年，Google颠覆性地提出了基于自注意力机制的神经网络结构——Transformer架构，奠定了大模型预训练算法架构的基础。

· 2018年，OpenAI和Google分别发布了GPT-1与BERT大模型，意味着预训练大模型成为自然语言处理领域的主流。在探索期，以Transformer为代表的全新神经网络架构，奠定了大模型的算法架构基础，使大模型技术的性能得到了显著提升。

迅猛发展期（2020-至今）：以GPT为代表的预训练大模型阶段

· 2020年，OpenAI公司推出了GPT-3，模型参数规模达到了1750亿，成为当时最大的语言模型，并且在零样本学习任务上实现了巨大性能提升。随后，更多策略如基于人类反馈的强化学习（RHLF）、代码预训练、指令微调等开始出现, 被用于进一步提高推理能力和任务泛化。

· 2022年11月，搭载了GPT3.5的ChatGPT横空出世，凭借逼真的自然语言交互与多场景内容生成能力，迅速引爆互联网。

· 2023年3月，最新发布的超大规模多模态预训练大模型——GPT-4，具备了多模态理解与多类型内容生成能力。在迅猛发展期，大数据、大算力和大算法完美结合，大幅提升了大模型的预训练和生成能力以及多模态多场景应用能力。如ChatGPT的巨大成功,就是在微软Azure强大的算力以及wiki等海量数据支持下，在Transformer架构基础上，坚持GPT模型及人类反馈的强化学习（RLHF）进行精调的策略下取得的。

4. 大模型的特点

· 巨大的规模: 大模型包含数十亿个参数，模型大小可以达到数百GB甚至更大。巨大的模型规模使大模型具有强大的表达能力和学习能力。

· 涌现能力：涌现（英语：emergence）或称创发、突现、呈展、演生，是一种现象，为许多小实体相互作用后产生了大实体，而这个大实体展现了组成它的小实体所不具有的特性。引申到模型层面，涌现能力指的是当模型的训练数据突破一定规模，模型突然涌现出之前小模型所没有的、意料之外的、能够综合分析和解决更深层次问题的复杂能力和特性，展现出类似人类的思维和智能。涌现能力也是大模型最显著的特点之一。

· 更好的性能和泛化能力： 大模型通常具有更强大的学习能力和泛化能力，能够在各种任务上表现出色，包括自然语言处理、图像识别、语音识别等。

· 多任务学习: 大模型通常会一起学习多种不同的NLP任务,如机器翻译、文本摘要、问答系统等。这可以使模型学习到更广泛和泛化的语言理解能力。

· 大数据训练: 大模型需要海量的数据来训练,通常在TB以上甚至PB级别的数据集。只有大量的数据才能发挥大模型的参数规模优势。

· 强大的计算资源: 训练大模型通常需要数百甚至上千个GPU,以及大量的时间,通常在几周到几个月。

· 迁移学习和预训练： 大模型可以通过在大规模数据上进行预训练，然后在特定任务上进行微调，从而提高模型在新任务上的性能。

· 自监督学习： 大模型可以通过自监督学习在大规模未标记数据上进行训练，从而减少对标记数据的依赖，提高模型的效能。

· 领域知识融合： 大模型可以从多个领域的数据中学习知识，并在不同领域中进行应用，促进跨领域的创新。

· 自动化和效率：大模型可以自动化许多复杂的任务，提高工作效率，如自动编程、自动翻译、自动摘要等。

5. 大模型的分类

按照输入数据类型的不同，大模型主要可以分为以下三大类：


· 语言大模型（NLP）：是指在自然语言处理（Natural Language Processing，NLP）领域中的一类大模型，通常用于处理文本数据和理解自然语言。这类大模型的主要特点是它们在大规模语料库上进行了训练，以学习自然语言的各种语法、语义和语境规则。例如：GPT系列（OpenAI）、Bard（Google）、文心一言（百度）。

· 视觉大模型（CV）：是指在计算机视觉（Computer Vision，CV）领域中使用的大模型，通常用于图像处理和分析。这类模型通过在大规模图像数据上进行训练，可以实现各种视觉任务，如图像分类、目标检测、图像分割、姿态估计、人脸识别等。例如：VIT系列（Google）、文心UFO、华为盘古CV、INTERN（商汤）。

· 多模态大模型：是指能够处理多种不同类型数据的大模型，例如文本、图像、音频等多模态数据。这类模型结合了NLP和CV的能力，以实现对多模态信息的综合理解和分析，从而能够更全面地理解和处理复杂的数据。例如：DingoDB多模向量数据库（九章云极DataCanvas）、DALL-E(OpenAI)、悟空画画（华为）、midjourney。

按照应用领域的不同，大模型主要可以分为L0、L1、L2三个层级：

· 通用大模型L0：是指可以在多个领域和任务上通用的大模型。它们利用大算力、使用海量的开放数据与具有巨量参数的深度学习算法，在大规模无标注数据上进行训练，以寻找特征并发现规律，进而形成可“举一反三”的强大泛化能力，可在不进行微调或少量微调的情况下完成多场景任务，相当于AI完成了“通识教育”。

· 行业大模型L1：是指那些针对特定行业或领域的大模型。它们通常使用行业相关的数据进行预训练或微调，以提高在该领域的性能和准确度，相当于AI成为“行业专家”。

· 垂直大模型L2：是指那些针对特定任务或场景的大模型。它们通常使用任务相关的数据进行预训练或微调，以提高在该任务上的性能和效果。

6. 大模型的泛化与微调

模型的泛化能力：是指一个模型在面对新的、未见过的数据时，能够正确理解和预测这些数据的能力。在机器学习和人工智能领域，模型的泛化能力是评估模型性能的重要指标之一。

什么是模型微调：给定预训练模型（Pre-trained model），基于模型进行微调（Fine Tune）。相对于从头开始训练(Training a model from scatch)，微调可以省去大量计算资源和计算时间，提高计算效率,甚至提高准确率。

模型微调的基本思想是使用少量带标签的数据对预训练模型进行再次训练，以适应特定任务。在这个过程中，模型的参数会根据新的数据分布进行调整。这种方法的好处在于，它利用了预训练模型的强大能力，同时还能够适应新的数据分布。因此，模型微调能够提高模型的泛化能力，减少过拟合现象。

常见的模型微调方法：

· Fine-tuning：这是最常用的微调方法。通过在预训练模型的最后一层添加一个新的分类层，然后根据新的数据集进行微调。

· Feature augmentation：这种方法通过向数据中添加一些人工特征来增强模型的性能。这些特征可以是手工设计的，也可以是通过自动特征生成技术生成的。

· Transfer learning：这种方法是使用在一个任务上训练过的模型作为新任务的起点，然后对模型的参数进行微调，以适应新的任务。

大模型是未来人工智能发展的重要方向和核心技术，未来，随着AI技术的不断进步和应用场景的不断拓展，大模型将在更多领域展现其巨大的潜力，为人类万花筒般的AI未来拓展无限可能性。
 
                        
原文链接：https://blog.csdn.net/weixin_46880696/article/details/134209440


https://github.com/gngpp/ninja


https://hong.greatdk.com/

## 分享

1. 百度的文心一言
2. 百川
3. kimichat 在中文上面很厉害
4. 腾讯的混元远远比不上百川 ，比开源的百川都差；
5. 字节被openai 封了调用openai的接口；张一鸣对AI很看重，豆包可能超过文心一言； 
6. 通用大模型，
7. AI Native的应用，目前想落地AI native应用
8. 阿里的通义千问，在B端市场可以，在C端不大行，现在开源130B 处于领先；
9. 华为的盘古，不咋样，国企可以用，没有市场化的场景；技术能力和市场、场景的匹配；盘古绑定了华为的国产芯片，生态也不好；
10. 科大讯飞 AI , 偏教育， 通用模型的能力不处于领先水平。
11. 算力分训练和推理2端的算力， 英伟达在训练这一块目前领先，国产不堪用； 推理端不依赖先进制程，功耗不敏感，国产芯片还行；

伟大不能被计划； 

做角色扮演的出海公司都没有亏损； 角色对话； 

动漫里面的； 

gpt 有价值观限制； 


二次元， 软色情，肥宅； 90后； 盗版内容满天飞， 

## token 

https://www.51cto.com/article/768678.html


## 向量数据库 


## 大语言模型的transformer 是怎么回事儿？ 



微调 ： 不是指参数的数量调整得少;

私有化部署一个模型； 


#  开源竞速：AI 大模型的「Linux 时刻」降临

https://foresightnews.pro/article/detail/34335



ChatGPT 发布后不久，Meta 就开源了类 GPT 大语言模型 LLaMA，此后，Alpaca、Vicuna、Koala 等多个大模型诞生，它们以远低于 ChatGPT 的模型规模和成本，实现了令人瞩目的性能，引发业内人士担忧「谷歌和 OpenAI 都没有护城河，大模型门槛正被开源踏破，不合作就会被取代」。资本市场也在关注大模型未来竞争格局如何，模型小了是否不再需要大量算力，数据在其中又扮演了什么角色？……本报告试图分析这波开源大语言模型风潮的共同点，回顾开源标杆 Linux 的发展史，回答这些问题。



共同点一：始于开源。开源≠免费，开源的商业模式至少包括：1、靠服务变现。曾上市、后被 IBM 收购的 Linux 企业服务公司红帽即是一例。企业为了更稳定和及时的技术支持，愿意付费。2、靠授权费变现。安卓开源，但谷歌向欧盟使用安卓谷歌套件的厂商收取许可费即是一例。3、许可证、标准和能力评价体系的发展，是开源大模型商用程度深化的催化剂。这波开源大模型采用的许可证协议主要是 Apache 2.0 和 MIT，它们不禁止商用，并且不禁止用户修改模型后闭源，这有助于公司应用此类大模型。



共同点二：参数少、小型化。相较于 GPT3+ 千亿参数超大模型，这波开源大模型的参数量普遍在十亿至百亿级别。目前尚没有一套系统的大模型性能评价体系，其中仅部分任务有公信力较强的评分标准。开源大模型中，Vicuna 的能力也较强，在部分任务能达到 92% GPT4 的效果。总体来说，OpenAI GPT 系仍一骑绝尘，但训练成本高，难复现。而开源大模型借助更大标识符训练数据集、DeepSpeed、RLHF 等方式，实现低训练成本和高性能，超大模型以下大模型的壁垒正在消失。



共同点三：数据集重视人类指令，并走向商用。ChatGPT 相较于 GPT3 效果大幅提升的重要因素是使用了 RLHF（基于人类反馈的强化学习），即在训练中，使用人类生成的答案和对 AI 生成内容的排序，来让 AI 「对齐」人类偏好。LLaMA 没有使用指令微调，但 LLaMA 之后的大量大模型使用并开源了指令数据集，并且逐步探索自建指令数据集，而非使用有商用限制的 OpenAI 的，进一步降低了复现 GPT 的门槛，扩展了商用可用性。



接下来怎么看开源大模型？站在开源大模型浪潮中，我们注意到两个趋势：1）与多模态融合，清华大学的 VisualGLM-6B 即是著名开源语言模型 ChatGLM 的多模态升级版，我们认为，其可基于消费级显卡在本地部署的特性是大势所趋。2）开源模型 + 边缘计算推动 AI 商用落地，哈尔滨大学的中文医疗问诊模型「华驼」以及在跨境电商的使用就是案例。



投资建议：我们认为，对大模型的看法应该分时、分层看待。1、短期内，OpenAI 的 GPT 系超大模型仍然超越众开源大模型，因此，应当重点关注与其在股权和产品上深度合作的微软、能获得 ChatGPTios App 收益分成的苹果，以及超大模型的算力服务商英伟达等；2、中长期来看，如果部分开源大模型能力被进一步验证，则应用将快速铺开，大模型对算力将形成正循环；3、其他：边缘算力、大数据公司和开源大模型服务商业态也值得关注。建议关注：1）光模块服务商：中际旭创、新易盛、天孚通信、源杰科技；2）智能模组服务商：美格智能、广和通；3）边缘 IDC 服务商：龙宇股份、网宿科技；4）AIoT 通信芯片及设备厂商：中兴通讯、紫光股份、锐捷网络、菲菱科思、工业富联、翱捷科技、初灵信息；5）应用端标的：恺英网络、神州泰岳、佳讯飞鸿、中科金财等。