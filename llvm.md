
## token 

https://www.51cto.com/article/768678.html


## 向量数据库 


## 大语言模型的transformer 是怎么回事儿？ 



微调 ： 不是指参数的数量调整得少;

私有化部署一个模型； 


#  开源竞速：AI 大模型的「Linux 时刻」降临

https://foresightnews.pro/article/detail/34335



ChatGPT 发布后不久，Meta 就开源了类 GPT 大语言模型 LLaMA，此后，Alpaca、Vicuna、Koala 等多个大模型诞生，它们以远低于 ChatGPT 的模型规模和成本，实现了令人瞩目的性能，引发业内人士担忧「谷歌和 OpenAI 都没有护城河，大模型门槛正被开源踏破，不合作就会被取代」。资本市场也在关注大模型未来竞争格局如何，模型小了是否不再需要大量算力，数据在其中又扮演了什么角色？……本报告试图分析这波开源大语言模型风潮的共同点，回顾开源标杆 Linux 的发展史，回答这些问题。



共同点一：始于开源。开源≠免费，开源的商业模式至少包括：1、靠服务变现。曾上市、后被 IBM 收购的 Linux 企业服务公司红帽即是一例。企业为了更稳定和及时的技术支持，愿意付费。2、靠授权费变现。安卓开源，但谷歌向欧盟使用安卓谷歌套件的厂商收取许可费即是一例。3、许可证、标准和能力评价体系的发展，是开源大模型商用程度深化的催化剂。这波开源大模型采用的许可证协议主要是 Apache 2.0 和 MIT，它们不禁止商用，并且不禁止用户修改模型后闭源，这有助于公司应用此类大模型。



共同点二：参数少、小型化。相较于 GPT3+ 千亿参数超大模型，这波开源大模型的参数量普遍在十亿至百亿级别。目前尚没有一套系统的大模型性能评价体系，其中仅部分任务有公信力较强的评分标准。开源大模型中，Vicuna 的能力也较强，在部分任务能达到 92% GPT4 的效果。总体来说，OpenAI GPT 系仍一骑绝尘，但训练成本高，难复现。而开源大模型借助更大标识符训练数据集、DeepSpeed、RLHF 等方式，实现低训练成本和高性能，超大模型以下大模型的壁垒正在消失。



共同点三：数据集重视人类指令，并走向商用。ChatGPT 相较于 GPT3 效果大幅提升的重要因素是使用了 RLHF（基于人类反馈的强化学习），即在训练中，使用人类生成的答案和对 AI 生成内容的排序，来让 AI 「对齐」人类偏好。LLaMA 没有使用指令微调，但 LLaMA 之后的大量大模型使用并开源了指令数据集，并且逐步探索自建指令数据集，而非使用有商用限制的 OpenAI 的，进一步降低了复现 GPT 的门槛，扩展了商用可用性。



接下来怎么看开源大模型？站在开源大模型浪潮中，我们注意到两个趋势：1）与多模态融合，清华大学的 VisualGLM-6B 即是著名开源语言模型 ChatGLM 的多模态升级版，我们认为，其可基于消费级显卡在本地部署的特性是大势所趋。2）开源模型 + 边缘计算推动 AI 商用落地，哈尔滨大学的中文医疗问诊模型「华驼」以及在跨境电商的使用就是案例。



投资建议：我们认为，对大模型的看法应该分时、分层看待。1、短期内，OpenAI 的 GPT 系超大模型仍然超越众开源大模型，因此，应当重点关注与其在股权和产品上深度合作的微软、能获得 ChatGPTios App 收益分成的苹果，以及超大模型的算力服务商英伟达等；2、中长期来看，如果部分开源大模型能力被进一步验证，则应用将快速铺开，大模型对算力将形成正循环；3、其他：边缘算力、大数据公司和开源大模型服务商业态也值得关注。建议关注：1）光模块服务商：中际旭创、新易盛、天孚通信、源杰科技；2）智能模组服务商：美格智能、广和通；3）边缘 IDC 服务商：龙宇股份、网宿科技；4）AIoT 通信芯片及设备厂商：中兴通讯、紫光股份、锐捷网络、菲菱科思、工业富联、翱捷科技、初灵信息；5）应用端标的：恺英网络、神州泰岳、佳讯飞鸿、中科金财等。